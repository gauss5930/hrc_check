import os
import re
import io
import json
import time
import base64
import hashlib
import pathlib
from typing import List, Dict, Tuple

import streamlit as st
from PIL import Image

# LiteLLM
try:
    from litellm import batch_completion
except Exception:
    batch_completion = None

# =====================================
# App / Paths
# =====================================
st.set_page_config(page_title="ë‹¤ë¬¸ì œ ìˆ˜ì§‘ Â· Judge Â· OCR (LiteLLM)", page_icon="ğŸ§ ", layout="wide")

APP_DATA_DIR = pathlib.Path("data")
RECORDS_DIR = APP_DATA_DIR / "records"
Q_CORRECT_DIR = APP_DATA_DIR / "correct_images"
Q_INCORRECT_DIR = APP_DATA_DIR / "incorrect_images"
ANS_IMG_DIR = APP_DATA_DIR / "answer_images"
CTX_IMG_DIR = APP_DATA_DIR / "context_images"
for d in [RECORDS_DIR, Q_CORRECT_DIR, Q_INCORRECT_DIR, ANS_IMG_DIR, CTX_IMG_DIR]:
    d.mkdir(parents=True, exist_ok=True)

# Default models
MODEL_SOLVE = "gemini/gemini-2.5-pro"
MODEL_JUDGE = "gemini/gemini-2.5-flash"
MODEL_OCR   = "gemini/gemini-2.5-pro"

SUPPORTED_IMG_TYPES = {"image/png", "image/jpeg", "image/jpg", "image/webp"}

# =====================================
# Utils
# =====================================
def sha16(b: bytes) -> str:
    return hashlib.sha256(b).hexdigest()[:16]

def sanitize(name: str) -> str:
    return re.sub(r"[^0-9A-Za-z._-]+", "_", name)

def infer_mime(name: str) -> str:
    n = name.lower()
    if n.endswith(".png"): return "image/png"
    if n.endswith(".jpg") or n.endswith(".jpeg"): return "image/jpeg"
    if n.endswith(".webp"): return "image/webp"
    return "image/jpeg"

def to_data_url(b: bytes, mime: str) -> str:
    return f"data:{mime};base64,{base64.b64encode(b).decode('utf-8')}"

def load_files(files) -> List[Dict]:
    out=[]
    for f in files or []:
        b = f.read(); f.seek(0)
        name = sanitize(getattr(f,"name", f"img_{sha16(b)}"))
        mime = getattr(f,"type", None) or infer_mime(name)
        out.append({"name": name, "mime": mime, "bytes": b})
    return out

def messages_for_images(prompt_text: str, images: List[Tuple[bytes, str]]) -> List[Dict]:
    content = [{"type":"text","text":prompt_text}]
    for b, m in images:
        content.append({"type":"image_url","image_url":{"url": to_data_url(b,m)}})
    return [{"role":"user","content": content}]

def extract_text_from_resp(resp) -> str:
    try:
        return resp["choices"][0]["message"]["content"]
    except Exception:
        try:
            ch0 = resp.choices[0]
            msg = getattr(ch0,"message",{})
            if isinstance(msg, dict): return msg.get("content","") or ""
            return getattr(msg,"content","") or ""
        except Exception:
            return ""

def build_solve_prompt() -> str:
    return (
        "ì—­í• : ë‹¤ì–‘í•œ í•™ê³¼ëª© ë¬¸ì œ í’€ì´ ë³´ì¡°\n"
        "ì§€ì‹œ:\n"
        "1) ë¬¸ì œì˜ ì¡°ê±´, ë³€ìˆ˜, ë‹¨ìœ„ë¥¼ ì •ë¦¬í•˜ê³  ê° ì§ˆë¬¸ì„ ë…ë¦½ì ìœ¼ë¡œ í’€ì´í•˜ì„¸ìš”.\n"
        "2) ê³„ì‚°ê³¼ ê·¼ê±°ì™€ ê³µì‹ì„ ë‹¨ê³„ë³„ë¡œ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”. ê°ê´€ì‹ì´ë©´ ì†Œê±°ë²• í›„ ë‚¨ì€ ë³´ê¸° ê²€ì¦.\n"
        "3) ë§ˆì§€ë§‰ì— í•œ ì¤„ë¡œ 'ìµœì¢… ì •ë‹µ:'ì„ í‘œê¸°í•˜ì„¸ìš”.\n"
        "ì¶”ê°€ ê°€ì •ì€ ìµœì†Œí™”í•˜ê³  ë³´ì´ëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."
    )

def build_ocr_prompt() -> str:
    return (
        "ì—­í• : OCR ì—”ì§„\n"
        "ì§€ì‹œì‚¬í•­: ì—…ë¡œë“œëœ ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë¥¼ ìˆëŠ” ê·¸ëŒ€ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.\n"
        "- ì¤„ë°”ê¿ˆê³¼ ë²ˆí˜¸ì™€ êµ¬ë¶„ì„ ê°€ëŠ¥í•œ ë³´ì¡´í•©ë‹ˆë‹¤.\n"
        "- ìˆ˜ì‹ê³¼ íŠ¹ìˆ˜ê¸°í˜¸ëŠ” ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¡œ í‘œê¸°í•©ë‹ˆë‹¤.\n"
        "- ì¤‘ìš” ì‚¬í•­: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ê³ , ì–´ë– í•œ í•´ì„¤ì´ë‚˜ ì„¤ëª…ë„ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”."
    )

def build_judge_prompt(model_solution: str, golden_answer_text: str, has_images: bool) -> str:
    """
    Golden answer ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ ì •ë‹µ ì—¬ë¶€ë¥¼ ì—„ë°€ íŒì •
    JSONë§Œ ì¶œë ¥
    """
    img_note = (
        "Golden Answerì—ëŠ” í…ìŠ¤íŠ¸ ì™¸ì—ë„ ì •ë‹µì„ ì„¤ëª…í•˜ê±°ë‚˜ ì¦ëª…í•˜ëŠ” ì´ë¯¸ì§€ê°€ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
        "ì´ë¯¸ì§€ì— ì íŒ ìˆ˜ì¹˜, ë‹¨ìœ„, í‘œê¸°, ì„ íƒì§€ ë¼ë²¨ì„ í•„ìš”ì‹œ ì½ì–´ ë°˜ì˜í•˜ì„¸ìš”.\n"
        if has_images else
        ""
    )
    return (
        "You are an impartial grading judge. Your task is to determine whether the model's final answer is correct "
        "based strictly on the provided Golden Answer.\n\n"
        + img_note +
        "Evaluation Procedures:\n"
        "1) Extract the model's FINAL answer from the solution transcript. The final line often contains a cue like "
        "'ìµœì¢… ì •ë‹µ:'. If missing, infer the last decisive numeric or algebraic result.\n"
        "2) Normalize both the model's final answer and the Golden Answer:\n"
        "   - Ignore non semantic punctuation and whitespace.\n"
        "   - Unify case and common synonyms such as trueì™€ ì°¸, falseì™€ ê±°ì§“.\n"
        "   - For numbers, ignore formatting differences like commas and leading zeros.\n"
        "   - Units must be semantically equivalent. If Golden Answer includes a unit, the model must match or be explicitly equivalent.\n"
        "3) Numeric tolerance:\n"
        "   - Default absolute tolerance is 1e-6, or relative tolerance 1 percent for non integer values, whichever is larger.\n"
        "4) Algebraic or format equivalence:\n"
        "   - Equivalent algebraic expressions are acceptable if identically valued.\n"
        "   - For multiple choice, letter or number labels must match the Golden Answer unless a clear mapping is proven.\n"
        "5) If the model's answer cannot be unambiguously mapped to the Golden Answer, mark as incorrect.\n\n"
        "Output strictly the following JSON object and nothing else:\n"
        '{"verdict":"correct|incorrect","model_final_answer":"...","explanation":"<=200 chars justification"}\n\n'
        "[MODEL_SOLUTION]\n" + model_solution + "\n\n"
        "[GOLDEN_ANSWER_TEXT]\n" + golden_answer_text + "\n"
        "If images are included below, consider their content as part of the Golden Answer."
    )

def parse_judge_json(text: str) -> Dict:
    try:
        data = json.loads(text)
        v = str(data.get("verdict","")).lower()
        if v not in ("correct","incorrect"):
            v = "correct" if "correct" in v else "incorrect"
        return {
            "verdict": v,
            "model_final_answer": data.get("model_final_answer",""),
            "explanation": data.get("explanation","")
        }
    except Exception:
        v = "correct" if "correct" in text.lower() and "incorrect" not in text.lower() else "incorrect"
        return {"verdict": v, "model_final_answer":"", "explanation": text[:200]}

# í•´ì‹œ ê¸°ë°˜ ê·¸ë£¹ ID ìƒì„±. ë™ì¼ ì…ë ¥ì´ë©´ ë™ì¼ group_idë¡œ ê³ ì •
def compute_group_id(q_items: List[Dict], ctx_items: List[Dict]) -> str:
    h = hashlib.sha256()
    for it in q_items or []:
        h.update(it["bytes"])
        h.update(it["name"].encode("utf-8"))
    for it in ctx_items or []:
        h.update(it["bytes"])
        h.update(it["name"].encode("utf-8"))
    return h.hexdigest()[:16]

def save_group_problem_images(q_items: List[Dict], indices: List[int], folder: pathlib.Path, group_id: str, p: int) -> List[str]:
    paths=[]
    for i, idx in enumerate(indices, start=1):
        it = q_items[idx]
        ext = ".png" if it["mime"]=="image/png" else ".jpg"
        path = folder / f"g{group_id}_p{p:02d}_{i:02d}{ext}"
        if not path.exists():
            with open(path,"wb") as w:
                w.write(it["bytes"])
        paths.append(str(path))
    return paths

def save_group_context_images(ctx_items: List[Dict], group_id: str) -> List[str]:
    paths=[]
    for i, it in enumerate(ctx_items, start=1):
        ext = ".png" if it["mime"]=="image/png" else ".jpg"
        path = CTX_IMG_DIR / f"g{group_id}_ctx_{i:02d}{ext}"
        if not path.exists():
            with open(path,"wb") as w:
                w.write(it["bytes"])
        paths.append(str(path))
    return paths

def save_group_answer_images(files, group_id: str, p: int) -> List[str]:
    saved=[]
    ts = int(time.time())
    for j, f in enumerate(files or [], start=1):
        b = f.read(); f.seek(0)
        name = sanitize(getattr(f,"name", f"a_{sha16(b)}"))
        mime = getattr(f,"type", None) or infer_mime(name)
        ext = ".png" if mime=="image/png" else ".jpg"
        out = ANS_IMG_DIR / f"g{group_id}_p{p:02d}_ans_{ts}_{j:02d}{ext}"
        if not out.exists():
            with open(out,"wb") as w:
                w.write(b)
        saved.append(str(out))
    return saved

def save_answer_items_from_bytes(items: List[Dict], group_id: str, p: int, tag: str="ansj") -> List[str]:
    """
    judge ë‹¨ê³„ì— ì—…ë¡œë“œëœ ì •ë‹µ ì´ë¯¸ì§€ì²˜ëŸ¼ ì´ë¯¸ ë°”ì´íŠ¸ë¡œ ë³´ìœ í•œ í•­ëª©ì„ ì €ì¥
    content hash ê¸°ë°˜ íŒŒì¼ëª…ìœ¼ë¡œ ì¤‘ë³µ ë°©ì§€
    """
    saved=[]
    for it in items or []:
        ext = ".png" if it["mime"]=="image/png" else ".jpg"
        fn = f"g{group_id}_p{p:02d}_{tag}_{sha16(it['bytes'])}{ext}"
        out = ANS_IMG_DIR / fn
        if not out.exists():
            with open(out,"wb") as w:
                w.write(it["bytes"])
        saved.append(str(out))
    return saved

def reset_to_initial(keep_settings=True):
    """
    experimental_rerun ì—†ì´ ì´ˆê¸°í™”. ì„¤ì •ë§Œ ìœ ì§€í•˜ê³  ì¬ì‹¤í–‰ ìœ ë„
    """
    keep_keys = {}
    if keep_settings:
        for k in ["api_env_name","api_key_value","model_solve","model_judge","model_ocr",
                  "n_problems","context_on","year_text"]:
            keep_keys[k] = st.session_state.get(k)
    st.session_state.clear()
    for k,v in keep_keys.items():
        st.session_state[k] = v

    try:
        st.rerun()
        return
    except Exception:
        pass

    try:
        ts = str(int(time.time()))
        try:
            st.query_params["_"] = ts
        except Exception:
            st.experimental_set_query_params(**{"_": ts})
    except Exception:
        st.warning("ì´ˆê¸°í™”ëŠ” ì™„ë£Œë˜ì—ˆì§€ë§Œ ìë™ ìƒˆë¡œê³ ì¹¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.")

# =====================================
# State
# =====================================
def init_state():
    st.session_state.setdefault("api_env_name", "GEMINI_API_KEY")
    st.session_state.setdefault("api_key_value", os.getenv("GEMINI_API_KEY",""))
    st.session_state.setdefault("model_solve", MODEL_SOLVE)
    st.session_state.setdefault("model_judge", MODEL_JUDGE)
    st.session_state.setdefault("model_ocr", MODEL_OCR)

    st.session_state.setdefault("n_problems", 1)
    st.session_state.setdefault("context_on", False)
    st.session_state.setdefault("year_text", "")

    st.session_state.setdefault("q_items", [])      
    st.session_state.setdefault("ctx_items", [])    
    st.session_state.setdefault("assignments", {})  

    st.session_state.setdefault("gt_answers", {})       
    st.session_state.setdefault("solve_outputs", {})    
    st.session_state.setdefault("judge_raw", {})        
    st.session_state.setdefault("judge_json", {})       

    st.session_state.setdefault("group_id", "")
    st.session_state.setdefault("saved_paths", {})      
    st.session_state.setdefault("question_texts", {})   
    st.session_state.setdefault("ctx_saved_paths", [])
    st.session_state.setdefault("ctx_ocr_text", "")
    st.session_state.setdefault("save_dir_for_current", "correct")

    # Judgeìš© ì •ë‹µ ì´ë¯¸ì§€ ë°”ì´íŠ¸ ì €ì¥ì†Œ {p: [ {name, mime, bytes}, ... ]}
    st.session_state.setdefault("judge_ans_items", {})

init_state()

# =====================================
# Sidebar
# =====================================
st.sidebar.title("âš™ï¸ ì„¤ì •")
st.sidebar.text_input("API Key Env Var Name", value=st.session_state.api_env_name, key="api_env_name")
st.sidebar.text_input("API Key Value", value=st.session_state.api_key_value, type="password", key="api_key_value")
st.sidebar.selectbox("í’€ì´ ëª¨ë¸", [st.session_state.model_solve, "openai/gpt-4o-mini"], index=0, key="model_solve")
st.sidebar.selectbox("Judge ëª¨ë¸", [st.session_state.model_judge, "openai/gpt-4o-mini"], index=0, key="model_judge")
st.sidebar.selectbox("OCR ëª¨ë¸", [st.session_state.model_ocr, "openai/gpt-4o-mini"], index=0, key="model_ocr")
st.sidebar.number_input("ë¬¸ì œ ê°œìˆ˜", min_value=1, max_value=50, value=st.session_state.n_problems, step=1, key="n_problems")
st.sidebar.checkbox("ì»¨í…ìŠ¤íŠ¸(ë¬¸ë‹¨) ì¡´ì¬", value=st.session_state.context_on, key="context_on")
st.sidebar.text_input("ì—°ë„(ì˜ˆ: 2023)", value=st.session_state.year_text, key="year_text")

# API Key ì£¼ì…
if st.session_state.api_env_name and st.session_state.api_key_value:
    os.environ[st.session_state.api_env_name] = st.session_state.api_key_value

# =====================================
# 0) ì—…ë¡œë“œ
# =====================================
st.title("ğŸ§  ë‹¤ë¬¸ì œ ìˆ˜ì§‘ Â· Judge Â· OCR (LiteLLM)")

st.markdown("### 0) ì´ë¯¸ì§€ ì—…ë¡œë“œ")
if st.session_state.context_on:
    c1, c2 = st.columns(2)
    with c1:
        q_files = st.file_uploader("ë¬¸ì œ ìŠ¤í¬ë¦°ìƒ· ì—…ë¡œë“œ (ë¯¸ë¦¬ë³´ê¸° ì—†ìŒ, ë‹¤ì¤‘)", type=["png","jpg","jpeg","webp"],
                                   accept_multiple_files=True, key="q_uploads")
        if q_files:
            st.session_state.q_items = load_files(q_files)
            st.caption("ë¬¸ì œ íŒŒì¼: " + (", ".join([x["name"] for x in st.session_state.q_items]) or "ì—†ìŒ"))
    with c2:
        ctx_files = st.file_uploader("ë¬¸ë‹¨(ì»¨í…ìŠ¤íŠ¸) ìŠ¤í¬ë¦°ìƒ· ì—…ë¡œë“œ (ë¯¸ë¦¬ë³´ê¸° ì—†ìŒ, ë‹¤ì¤‘)", type=["png","jpg","jpeg","webp"],
                                     accept_multiple_files=True, key="ctx_uploads")
        if ctx_files:
            st.session_state.ctx_items = load_files(ctx_files)
            st.caption("ì»¨í…ìŠ¤íŠ¸ íŒŒì¼: " + (", ".join([x["name"] for x in st.session_state.ctx_items]) or "ì—†ìŒ"))
else:
    q_files = st.file_uploader("ë¬¸ì œ ìŠ¤í¬ë¦°ìƒ· ì—…ë¡œë“œ (ë¯¸ë¦¬ë³´ê¸° ì—†ìŒ, ë‹¤ì¤‘)", type=["png","jpg","jpeg","webp"],
                               accept_multiple_files=True, key="q_uploads_alone")
    if q_files:
        st.session_state.q_items = load_files(q_files)
        st.caption("ë¬¸ì œ íŒŒì¼: " + (", ".join([x["name"] for x in st.session_state.q_items]) or "ì—†ìŒ"))

if not st.session_state.q_items:
    st.info("ë¬¸ì œ ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

# =====================================
# 1) ë¬¸ì œ êµ¬ì„±
# =====================================
st.markdown("### 1) ë¬¸ì œ êµ¬ì„± (ë¬¸ì œë³„ ì´ë¯¸ì§€ ì„ íƒ)")
names = [it["name"] for it in st.session_state.q_items]
for p in range(1, st.session_state.n_problems+1):
    default_sel = st.session_state.assignments.get(p, [])
    st.session_state.assignments[p] = st.multiselect(
        f"ë¬¸ì œ {p}ì— í¬í•¨ë  ì´ë¯¸ì§€",
        options=list(range(len(names))),
        default=default_sel,
        format_func=lambda idx: names[idx],
        key=f"assign_{p}"
    )

# =====================================
# 2) í’€ì´ì™€ Judge
# =====================================
st.markdown("***")
st.markdown("### 2) ëª¨ë“  ë¬¸ì œ í’€ì´ ì‹œì‘ (ë°°ì¹˜) + LLM as a Judge")

# Judgeìš© ì •ë‹µ ì…ë ¥ UI: ì¢Œì¸¡ í…ìŠ¤íŠ¸, ìš°ì¸¡ ì´ë¯¸ì§€
for p in range(1, st.session_state.n_problems+1):
    if not st.session_state.assignments.get(p):
        continue
    c1, c2 = st.columns([3,2], gap="large")
    with c1:
        st.session_state.gt_answers[p] = st.text_area(
            f"[ë¬¸ì œ {p}] ì •ë‹µ í…ìŠ¤íŠ¸ ì…ë ¥ LLM as a Judgeìš© í•„ìˆ˜",
            value=st.session_state.gt_answers.get(p, ""),
            height=140,
            key=f"gt_{p}"
        )
    with c2:
        judge_files = st.file_uploader(
            f"[ë¬¸ì œ {p}] ì •ë‹µ ì´ë¯¸ì§€ ì—…ë¡œë“œ LLM as a Judgeìš© ì„ íƒ",
            type=["png","jpg","jpeg","webp"],
            accept_multiple_files=True,
            key=f"gt_imgs_{p}"
        )
        if judge_files:
            st.session_state.judge_ans_items[p] = load_files(judge_files)
        names_j = [it["name"] for it in st.session_state.judge_ans_items.get(p, [])]
        st.caption("íŒì •ìš© ì •ë‹µ ì´ë¯¸ì§€: " + (", ".join(names_j) if names_j else "ì—†ìŒ"))

run_btn = st.button("ğŸ§  ëª¨ë“  ë¬¸ì œ í’€ì´ì™€ ì±„ì  ì‹¤í–‰", use_container_width=True, type="primary")
if run_btn:
    if batch_completion is None:
        st.error("litellm ë¯¸ì„¤ì¹˜: pip install litellm")
        st.stop()

    missing = [p for p in range(1, st.session_state.n_problems+1)
               if st.session_state.assignments.get(p) and not (st.session_state.gt_answers.get(p) or "").strip()]
    if missing:
        st.error(f"ëª¨ë“  ì •ë‹µ í…ìŠ¤íŠ¸ ë°•ìŠ¤ì— ê°’ì„ ì…ë ¥í•˜ì„¸ìš”. ëˆ„ë½: {missing}")
        st.stop()

    # 2-1) í’€ì´ ë°°ì¹˜
    solve_tasks, solve_pids = [], []
    for p in range(1, st.session_state.n_problems+1):
        idxs = st.session_state.assignments.get(p, [])
        if not idxs: continue
        images = [(st.session_state.q_items[i]["bytes"], st.session_state.q_items[i]["mime"]) for i in idxs]
        solve_tasks.append(messages_for_images(build_solve_prompt(), images))
        solve_pids.append(p)

    if solve_tasks:
        with st.spinner("ë¬¸ì œ í’€ì´ ì¤‘..."):
            try:
                solve_resps = batch_completion(
                    model=st.session_state.model_solve,
                    messages=solve_tasks,
                    temperature=0.6, top_p=0.95, max_tokens=16384
                )
                for p, resp in zip(solve_pids, solve_resps):
                    st.session_state.solve_outputs[p] = extract_text_from_resp(resp)
            except Exception as e:
                st.error(f"í’€ì´ ë°°ì¹˜ ì˜¤ë¥˜: {e}")

    # 2-2) Judge ë°°ì¹˜ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ë™ì‹œ ì œê³µ
    judge_tasks, judge_pids = [], []
    for p in range(1, st.session_state.n_problems+1):
        if not st.session_state.assignments.get(p): 
            continue
        model_out = st.session_state.solve_outputs.get(p, "")
        golden_text = st.session_state.gt_answers.get(p, "")
        j_items = st.session_state.judge_ans_items.get(p, [])
        j_imgs = [(it["bytes"], it["mime"]) for it in j_items]
        judge_prompt = build_judge_prompt(model_out, golden_text, has_images=bool(j_imgs))
        judge_tasks.append(messages_for_images(judge_prompt, j_imgs))
        judge_pids.append(p)

    if judge_tasks:
        with st.spinner("ì±„ì  ì¤‘..."):
            try:
                judge_resps = batch_completion(
                    model=st.session_state.model_judge,
                    messages=judge_tasks,
                    temperature=0.0, max_tokens=4096
                )
                for p, resp in zip(judge_pids, judge_resps):
                    raw = extract_text_from_resp(resp)
                    st.session_state.judge_raw[p] = raw
                    st.session_state.judge_json[p] = parse_judge_json(raw)
            except Exception as e:
                st.error(f"Judge ë°°ì¹˜ ì˜¤ë¥˜: {e}")

# ê²°ê³¼ í‘œì‹œ
if st.session_state.solve_outputs or st.session_state.judge_json:
    st.markdown("#### ê²°ê³¼ ìš”ì•½")
for p in range(1, st.session_state.n_problems+1):
    if not st.session_state.assignments.get(p): continue
    s_out = st.session_state.solve_outputs.get(p, "")
    j_out = st.session_state.judge_raw.get(p, "")
    if s_out:
        st.text_area(f"[ë¬¸ì œ {p}] ëª¨ë¸ í’€ì´ ê²°ê³¼", value=s_out, height=260, key=f"solve_out_{p}")
    if j_out:
        st.text_area(f"[ë¬¸ì œ {p}] Judge ì¶œë ¥ JSON", value=j_out, height=200, key=f"judge_out_{p}")

# =====================================
# 3) íŒë³„ ë²„íŠ¼
# =====================================
if st.session_state.judge_json:
    col_ok, col_no = st.columns(2)
    with col_ok:
        correct_btn = st.button("âœ… ì •ë‹µ ì´ë¯¸ì§€ ì €ì¥ ë° ì´ˆê¸°í™”", use_container_width=True, type="secondary")
    with col_no:
        wrong_btn = st.button("âŒ ì˜¤ë‹µ ì´ë¯¸ì§€ ì €ì¥ ë° OCR ì§„í–‰", use_container_width=True)

    # í•´ì‹œ ê¸°ë°˜ group_id ë¶€ì—¬. ë™ì¼ ì…ë ¥ì´ë©´ ë™ì¼ ê°’
    if (correct_btn or wrong_btn) and not st.session_state.group_id:
        st.session_state.group_id = compute_group_id(st.session_state.q_items, st.session_state.ctx_items)

    if correct_btn:
        for p in range(1, st.session_state.n_problems+1):
            idxs = st.session_state.assignments.get(p, [])
            if not idxs: continue
            save_group_problem_images(st.session_state.q_items, idxs, Q_CORRECT_DIR, st.session_state.group_id, p)
        if st.session_state.context_on and st.session_state.ctx_items:
            save_group_context_images(st.session_state.ctx_items, st.session_state.group_id)
        st.session_state.save_dir_for_current = "correct"
        st.success("ì •ë‹µ ì²˜ë¦¬ ì™„ë£Œ. ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
        reset_to_initial(keep_settings=True)

    if wrong_btn:
        # ë¬¸ì œ ì´ë¯¸ì§€ë¥¼ ì˜¤ë‹µ í´ë”ì— ì €ì¥
        for p in range(1, st.session_state.n_problems+1):
            idxs = st.session_state.assignments.get(p, [])
            if not idxs: continue
            saved = save_group_problem_images(st.session_state.q_items, idxs, Q_INCORRECT_DIR, st.session_state.group_id, p)
            st.session_state.saved_paths[p] = saved

        if st.session_state.context_on and st.session_state.ctx_items:
            st.session_state.ctx_saved_paths = save_group_context_images(st.session_state.ctx_items, st.session_state.group_id)

        # OCR ìˆ˜í–‰
        ocr_tasks, ocr_pids = [], []
        ocr_prompt = build_ocr_prompt()
        for p in range(1, st.session_state.n_problems+1):
            idxs = st.session_state.assignments.get(p, [])
            if not idxs: continue
            images = [(st.session_state.q_items[i]["bytes"], st.session_state.q_items[i]["mime"]) for i in idxs]
            ocr_tasks.append(messages_for_images(ocr_prompt, images))
            ocr_pids.append(p)

        if ocr_tasks:
            if batch_completion is None:
                st.error("litellm ë¯¸ì„¤ì¹˜: pip install litellm")
                st.stop()
            with st.spinner("ì˜¤ë‹µìœ¼ë¡œ ë¶„ë¥˜ë¨. OCR ì‹¤í–‰ ì¤‘..."):
                try:
                    ocr_resps = batch_completion(
                        model=st.session_state.model_ocr,
                        messages=ocr_tasks,
                        temperature=0.0, max_tokens=16384
                    )
                    for p, resp in zip(ocr_pids, ocr_resps):
                        st.session_state.question_texts[p] = extract_text_from_resp(resp)
                except Exception as e:
                    st.error(f"OCR ì˜¤ë¥˜: {e}")

        # ì»¨í…ìŠ¤íŠ¸ OCR
        if st.session_state.context_on and st.session_state.ctx_items:
            if not st.session_state.ctx_ocr_text:
                ctx_msgs = messages_for_images(ocr_prompt, [(it["bytes"], it["mime"]) for it in st.session_state.ctx_items])
                try:
                    ctx_resp = batch_completion(
                        model=st.session_state.model_ocr,
                        messages=[ctx_msgs],
                        temperature=0.0, max_tokens=16384
                    )[0]
                    st.session_state.ctx_ocr_text = extract_text_from_resp(ctx_resp)
                except Exception as e:
                    st.error(f"ì»¨í…ìŠ¤íŠ¸ OCR ì˜¤ë¥˜: {e}")

        st.session_state.save_dir_for_current = "incorrect"
        st.success("ì˜¤ë‹µ ì²˜ë¦¬ ì™„ë£Œ. ì•„ë˜ 4ë‹¨ê³„ì—ì„œ ê²€ìˆ˜ í›„ ì €ì¥í•˜ì„¸ìš”.")

# =====================================
# 4) ë¬¸í•­ í…ìŠ¤íŠ¸ ê²€ìˆ˜ ë° ì •ë‹µ ì…ë ¥
# =====================================
st.markdown("***")
st.markdown("### 4) ë¬¸í•­ í…ìŠ¤íŠ¸ ê²€ìˆ˜ ë° ì •ë‹µ ì…ë ¥")

for p in range(1, st.session_state.n_problems+1):
    if not st.session_state.assignments.get(p):
        continue
    st.markdown(f"#### ë¬¸ì œ {p}")

    # ë¬¸í•­ í…ìŠ¤íŠ¸
    default_qtext = st.session_state.question_texts.get(p, "")
    st.text_area(f"[ë¬¸ì œ {p}] ë¬¸í•­ í…ìŠ¤íŠ¸ ê²€ìˆ˜", value=default_qtext, height=220, key=f"qtext_{p}")

    # ë¬¸í•­ ì´ë¯¸ì§€ ë§¤í•‘
    saved = st.session_state.saved_paths.get(p, [])
    if saved:
        options = saved
        default = saved
        fmt = lambda path: pathlib.Path(path).name
    else:
        idxs = st.session_state.assignments.get(p, [])
        options = idxs
        default = idxs
        fmt = lambda idx: names[idx]
    st.multiselect(
        f"[ë¬¸ì œ {p}] í…ìŠ¤íŠ¸ì™€ ì—°ê²°í•  ë¬¸ì œ ì´ë¯¸ì§€",
        options=options,
        default=default,
        format_func=fmt,
        key=f"qimgs_{p}"
    )

    # ì •ë‹µ ì…ë ¥ UI ì¢Œìš° ë°°ì¹˜
    c1, c2 = st.columns([3,2], gap="large")
    with c1:
        prefill_ans = st.session_state.gt_answers.get(p, "")
        st.text_area(f"[ë¬¸ì œ {p}] ì •ë‹µ í…ìŠ¤íŠ¸", value=prefill_ans, height=160, key=f"ans_text_{p}")
    with c2:
        # Judge ë‹¨ê³„ì—ì„œ ì˜¬ë¦° ì´ë¯¸ì§€ í¬í•¨ ì—¬ë¶€
        has_judge_imgs = bool(st.session_state.judge_ans_items.get(p))
        include_default = True
        st.checkbox(
            f"[ë¬¸ì œ {p}] Judge ë‹¨ê³„ì˜ ì •ë‹µ ì´ë¯¸ì§€ í¬í•¨",
            value=include_default if has_judge_imgs else False,
            key=f"include_jimg_{p}",
            disabled=not has_judge_imgs
        )
        names_j = [it["name"] for it in st.session_state.judge_ans_items.get(p, [])]
        if names_j:
            st.caption("í¬í•¨ ì˜ˆì •: " + ", ".join(names_j))
        # ì¶”ê°€ ì—…ë¡œë“œ
        st.file_uploader(
            f"[ë¬¸ì œ {p}] ì¶”ê°€ ì •ë‹µ ì´ë¯¸ì§€ ì—…ë¡œë“œ",
            type=["png","jpg","jpeg","webp"],
            accept_multiple_files=True,
            key=f"ans_imgs_{p}"
        )

# ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸
if st.session_state.context_on:
    st.markdown("#### ì»¨í…ìŠ¤íŠ¸ ë¬¸ë‹¨")
    st.text_area("ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ê²€ìˆ˜", value=st.session_state.ctx_ocr_text, height=220, key="ctx_text_review")

# =====================================
# 5) ìµœì¢… ì €ì¥
# =====================================
st.markdown("***")
st.markdown("### 5) ìµœì¢… ì €ì¥")

save_btn = st.button("ğŸ’¾ JSON ì €ì¥", type="primary", use_container_width=True)
if save_btn:
    if not st.session_state.group_id:
        st.session_state.group_id = compute_group_id(st.session_state.q_items, st.session_state.ctx_items)

    # í•œ ë¬¸ë‹¨ ê¸°ì¤€ìœ¼ë¡œ í•˜ë‚˜ì˜ JSON íŒŒì¼
    if st.session_state.context_on:
        if not st.session_state.ctx_saved_paths and st.session_state.ctx_items:
            st.session_state.ctx_saved_paths = save_group_context_images(st.session_state.ctx_items, st.session_state.group_id)
        context_block = {
            "text": st.session_state.get("ctx_text_review", st.session_state.ctx_ocr_text),
            "image": st.session_state.ctx_saved_paths or []
        }
    else:
        context_block = ""

    year_val = st.session_state.year_text.strip()

    questions_payload = []
    for p in range(1, st.session_state.n_problems+1):
        if not st.session_state.assignments.get(p):
            continue

        # ë¬¸í•­ í…ìŠ¤íŠ¸
        q_text = st.session_state.get(f"qtext_{p}", "").strip()

        # ë¬¸ì œ ì´ë¯¸ì§€ ê²½ë¡œ
        selected = st.session_state.get(f"qimgs_{p}", []) or []
        if selected and isinstance(selected[0], str):
            q_imgs_paths = selected
        elif selected:
            target_dir = Q_CORRECT_DIR if st.session_state.get("save_dir_for_current") != "incorrect" else Q_INCORRECT_DIR
            idxs = [int(x) for x in selected]
            q_imgs_paths = save_group_problem_images(st.session_state.q_items, idxs, target_dir, st.session_state.group_id, p)
        else:
            q_imgs_paths = []

        # ì •ë‹µ í…ìŠ¤íŠ¸
        a_text = st.session_state.get(f"ans_text_{p}", "").strip()

        # ì •ë‹µ ì´ë¯¸ì§€ ê²½ë¡œ
        a_imgs_paths = []

        # 1) Judge ë‹¨ê³„ì—ì„œ ì˜¬ë¦° ì´ë¯¸ì§€ í¬í•¨
        if st.session_state.get(f"include_jimg_{p}", False):
            a_imgs_paths += save_answer_items_from_bytes(
                st.session_state.judge_ans_items.get(p, []),
                st.session_state.group_id,
                p,
                tag="ansj"
            )

        # 2) 4ë‹¨ê³„ì—ì„œ ì¶”ê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ ì €ì¥
        ans_files = st.session_state.get(f"ans_imgs_{p}", [])
        a_imgs_paths += save_group_answer_images(ans_files, st.session_state.group_id, p)

        questions_payload.append({
            "text": q_text,
            "text_image": q_imgs_paths,
            "answer": a_text,
            "answer_image": a_imgs_paths
        })

    group_obj = [{
        "context": context_block,
        "question": questions_payload,
        "year": year_val
    }]

    out_path = RECORDS_DIR / f"bundle_{st.session_state.group_id}.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(group_obj, f, ensure_ascii=False, indent=2)

    st.success(f"ì €ì¥ ì™„ë£Œ: {out_path}")
    reset_to_initial(keep_settings=True)
